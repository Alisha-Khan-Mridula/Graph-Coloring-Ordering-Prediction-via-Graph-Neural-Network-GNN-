{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZBnPIV1aJ5cQvqpA9lR5B"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNak8WDmo01C",
        "outputId": "03e1ea66-656e-4407-fa72-dcaa9d51d12e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-$(torch --version | awk -F '[: ]+' '{print $3}')+cu$(nvidia-smi --query-gpu=driver_version --format=csv,noheader | awk -F '.' '{print $1$2}')/torch_stable.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQeJI0u7pDaY",
        "outputId": "2ccc1d49-7de6-4da4-c7b2-7c144ce2ba4a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: torch: command not found\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "Looking in links: https://data.pyg.org/whl/torch-+cu/torch_stable.html\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-cluster\n",
            "  Downloading torch_cluster-1.6.3.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-spline-conv\n",
            "  Downloading torch_spline_conv-1.2.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch-scatter, torch-sparse, torch-cluster, torch-spline-conv\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl size=537340 sha256=6ce006d0e026e94d0c4fbc0d1fa4bd98cce1ec5cdec291d2b037c2cc4896e607\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/f1/2b/3b46d54b134259f58c8363568569053248040859b1a145b3ce\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp310-cp310-linux_x86_64.whl size=1111457 sha256=64e08463f96bb6f56c85b66c48f7b698e5dffba960fe286ccf51ee6431554cc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/dd/0f/a6a16f9f3b0236733d257b4b4ea91b548b984a341ed3b8f38c\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.6.3-cp310-cp310-linux_x86_64.whl size=731660 sha256=c2b1a389e5c135071abaef6ec97213c99d270def334781b684d37ba3a79fef77\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/78/c3/536637b3cdcc3313aa5e8851a6c72b97f6a01877e68c7595e3\n",
            "  Building wheel for torch-spline-conv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-spline-conv: filename=torch_spline_conv-1.2.2-cp310-cp310-linux_x86_64.whl size=225391 sha256=2417dc95fe40ce385e6999ba123b3ae8b3afaa490c6606acdf4ec3acd9066229\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/34/be/187e4b5f5ccefecca2c1a5dfc8da244ec50baa1f33c7b8c9a1\n",
            "Successfully built torch-scatter torch-sparse torch-cluster torch-spline-conv\n",
            "Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster, torch-geometric\n",
            "Successfully installed torch-cluster-1.6.3 torch-geometric-2.6.1 torch-scatter-2.1.2 torch-sparse-0.6.18 torch-spline-conv-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Connection\n",
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "dataset_name = 'Cora'\n",
        "dataset = Planetoid(root='data/' + dataset_name, name=dataset_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv2cVVch0dfx",
        "outputId": "3288fece-10d7-461c-e00e-989b88dd0feb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z-m4lPmR0f3",
        "outputId": "f5531ce9-f42a-4a09-d056-6cfd8393bb93"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle as pkl\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "import sys\n",
        "from scipy import sparse\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Data Loading\n",
        "data = dataset[0]\n",
        "objects = []\n",
        "#Node features\n",
        "node_features = data.x\n",
        "objects.append(node_features)\n",
        "#Node labels\n",
        "node_labels = data.y\n",
        "objects.append(node_labels)\n",
        "#Adjacency Matrix (Graph adjacency information)\n",
        "graph = data.edge_index\n",
        "#objects.append(graph)\n",
        "\n",
        "node_features, node_labels = tuple(objects)\n",
        "\n",
        "#Data Preprocessing\n",
        "features = sparse.csr_matrix(node_features)\n",
        "test_idx_reorder = data.test_mask.nonzero(as_tuple=False).view(-1).numpy()\n",
        "test_idx_range = np.sort(test_idx_reorder)\n",
        "\n",
        "features[test_idx_reorder, :] = features[test_idx_range, :]\n",
        "\n",
        "#row features normalization\n",
        "row_sum = np.array(features.sum(1))\n",
        "row_inv = np.power(row_sum, -1).flatten()\n",
        "row_inv[np.isinf(row_inv)] = 0.\n",
        "row_mat_inv = sp.diags(row_inv)\n",
        "features = row_mat_inv.dot(features)\n",
        "features = features.todense()\n",
        "\n",
        "\n",
        "nb_nodes = features.shape[0]\n",
        "ft_size = features.shape[1]\n",
        "batch_size = 1\n",
        "hid_units = [8] #No of output size\n",
        "n_heads = [8, 1]\n",
        "nonlinearity = tf.nn.elu\n",
        "residual = False\n",
        "\n",
        "#Defining Input layers\n",
        "# feature_input_shape = (batch_size, nb_nodes, ft_size)\n",
        "# feature_input= layers.Input(shape=feature_input_shape[1:])\n",
        "\n",
        "# bias_input = layers.Input(shape=(batch_size, nb_nodes, nb_nodes))\n",
        "\n",
        "feature_input = tf.keras.Input(shape=(nb_nodes, ft_size), batch_size=batch_size)\n",
        "bias_input = tf.keras.Input(shape=(nb_nodes, nb_nodes), batch_size=batch_size)\n",
        "\n",
        "#Defining dropout rates\n",
        "ffd_drop = 0.0\n",
        "attn_drop = 0.0\n",
        "\n",
        "seq = feature_input\n",
        "\n",
        "\n",
        "conv1d = layers.Conv1D #layers.Conv1D\n",
        "\n",
        "# Attention Mechanism\n",
        "def attn_head(seq, bias_mat, out_sz, activation, in_drop=0.0, coef_drop=0.0, residual=False):\n",
        "  with tf.name_scope('my_attn'):\n",
        "          # Apply dropout if needed\n",
        "          if in_drop != 0.0:\n",
        "              seq = tf.nn.dropout(seq, 1.0 - in_drop)\n",
        "\n",
        "          seq_fts = layers.Conv1D(filters=out_sz, kernel_size=1, use_bias=False)(seq)\n",
        "\n",
        "          # Self-attention mechanism\n",
        "          f_1 = layers.Conv1D(filters=1, kernel_size=1)(seq_fts)\n",
        "          f_2 = layers.Conv1D(filters=1, kernel_size=1)(seq_fts)\n",
        "\n",
        "          f_2_transposed = layers.Lambda(lambda x: tf.transpose(x, perm=[0, 2, 1]))(f_2)\n",
        "          logits = layers.Add()([f_1, f_2_transposed])\n",
        "\n",
        "          leaky_relu = layers.LeakyReLU(alpha=0.2)\n",
        "          logits_with_bias = layers.Add()([logits, bias_mat])\n",
        "          coefs = layers.Activation('softmax')(leaky_relu(logits_with_bias))\n",
        "          coefs_reshaped = layers.Reshape((2708, 2708))(coefs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          if coef_drop != 0.0:\n",
        "              coefs = tf.nn.dropout(coefs, 1.0 - coef_drop)\n",
        "\n",
        "          # Matrix Multiplication\n",
        "          vals = layers.Dot(axes=[1,1])([coefs_reshaped, seq_fts])\n",
        "          #ret = vals\n",
        "\n",
        "          # add_layer = tf.keras.layers.Add()\n",
        "          # ret = add_layer([vals, bias_mat])\n",
        "\n",
        "          # Residual connection using tf.cond\n",
        "          if residual:\n",
        "              ret = tf.cond(\n",
        "                  tf.shape(seq)[-1] != tf.shape(ret)[-1],  # Condition\n",
        "                  lambda: ret + layers.Conv1D(tf.shape(ret)[-1], 1)(seq),  # If true\n",
        "                  lambda: ret + seq  # If false\n",
        "              )\n",
        "\n",
        "          if isinstance(activation, str):\n",
        "            ret = layers.Activation(activation)(vals)  # If activation is a string name\n",
        "          else:\n",
        "            activation_layer = CustomActivation()\n",
        "            ret = activation_layer(vals)\n",
        "\n",
        "          return ret, coefs\n",
        "\n",
        "class CustomActivation(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return tf.nn.leaky_relu(inputs, alpha=0.2)\n",
        "\n",
        "output, attention_weights  = attn_head(seq, bias_mat=bias_input,\n",
        "              out_sz=hid_units[0], activation=nonlinearity,\n",
        "              in_drop=ffd_drop, coef_drop=attn_drop, residual=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WenyiOQG1Iap",
        "outputId": "c035576b-b35f-45f8-8623-379051494cd1"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=[feature_input, bias_input], outputs=[output, attention_weights])\n",
        "feature_input_pred = tf.random.normal(shape=(batch_size, nb_nodes, ft_size))\n",
        "bias_input_pred = tf.random.normal(shape=(batch_size, nb_nodes, nb_nodes))\n",
        "result, attention_weights  = model.predict([feature_input_pred, bias_input_pred]) #result presents the posibilites of nodes belonging to different classes\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayoatim2q7_T",
        "outputId": "431db4bd-daf5-4c2c-f8b0-8a4baae1d1a3"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e32200af0a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
            "[[[-5.93792181e-03  1.33593967e-02  7.56769581e-03 ...  1.49006033e-02\n",
            "   -2.22952847e-04 -6.50201458e-03]\n",
            "  [ 3.86376167e-04 -1.23089720e-02  3.65208648e-02 ...  9.33311656e-02\n",
            "    6.25395998e-02 -1.31424805e-02]\n",
            "  [ 3.31265032e-02  2.44479589e-02  3.03144865e-02 ...  4.48021181e-02\n",
            "    2.53930734e-03  3.45284306e-02]\n",
            "  ...\n",
            "  [ 2.98298895e-04 -5.88089507e-03  1.42798899e-02 ...  4.23757397e-02\n",
            "    2.99689248e-02 -6.09180797e-03]\n",
            "  [-9.39240563e-05 -1.31790508e-02  3.49502563e-02 ...  9.49009731e-02\n",
            "    6.11336567e-02 -1.29420180e-02]\n",
            "  [-2.45917327e-04 -1.37911802e-02  3.31422053e-02 ...  9.76806954e-02\n",
            "    6.19298741e-02 -1.21397590e-02]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Attention weights from one node to all other nodes\n",
        "node_index = 40  # Index of the node you want to inspect\n",
        "print(f\"Attention weights for node {node_index} to its neighbors:\")\n",
        "print(attention_weights[0, node_index, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmy7sg9-vfH2",
        "outputId": "dfc6e3c5-41ba-45e1-f5de-5a73de015940"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights for node 40 to its neighbors:\n",
            "[0.00016312 0.00020975 0.00015461 ... 0.00014715 0.00173849 0.00021143]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention weights between two nodes\n",
        "edge_example = edge_index[:, np.where(edge_index[0]==40)[0]]\n",
        "print(edge_example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpJU9JMnCI1H",
        "outputId": "c2b89fc8-1a76-4d85-c534-8b313851b9a3"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  40,   40,   40],\n",
            "        [ 507,  866, 1364]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_index_1 = edge_example[0][0]\n",
        "node_index_2 = edge_example[1][0]\n",
        "print(f\"Attention weights for node {node_index_1} to {node_index_2}\")\n",
        "print(attention_weights[0, node_index_1, node_index_2 ])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LubWXhaWC0EH",
        "outputId": "3d892437-3c37-441e-ec54-ce328264d90e"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights for node 40 to 507\n",
            "5.1700645e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index = dataset[0].edge_index\n",
        "node_features = dataset[0].x\n",
        "\n",
        "# Create a NetworkX graph from the edge index\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add edges to the graph from the edge_index\n",
        "for i in range(edge_index.shape[1]):\n",
        "    src = edge_index[0, i].item()  # Source node\n",
        "    dst = edge_index[1, i].item()  # Destination node\n",
        "    G.add_edge(src, dst)\n",
        "\n",
        "# Get the adjacency matrix as a sparse matrix\n",
        "adjacency_matrix = nx.adjacency_matrix(G)\n",
        "\n",
        "# Print the shape of the adjacency matrix\n",
        "print(adjacency_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeAy4KgG4gA3",
        "outputId": "73d6537a-50d0-4cdd-f9ee-3e8bf74c23e4"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2708, 2708)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LVrY6mp7Evm",
        "outputId": "743e16f2-556e-4b15-a5ca-01160a2629e8"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 633, 1862, 2582,  ...,  598, 1473, 2706],\n",
            "        [   0,    0,    0,  ..., 2707, 2707, 2707]])\n"
          ]
        }
      ]
    }
  ]
}